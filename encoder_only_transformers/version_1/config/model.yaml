model:
  vocab_size: 30522
  d_model: 128
  num_heads: 8
  d_ff: 512
  num_layers: 4
  num_classes: 4
  max_seq_len: 384
  dropout: 0.1
  tokenizer: "bert-base-uncased"